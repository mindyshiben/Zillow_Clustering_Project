{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d45064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessary to acquire, prepare, explore, visualize, analyze, and model data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import env\n",
    "import acquire\n",
    "import prepare \n",
    "\n",
    "from tabulate import tabulate\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49634a7",
   "metadata": {},
   "source": [
    "using functions created to acquire and wrangle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53f77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feef4c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.propertycountylandusecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03229e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_zillow_data()\n",
    "\n",
    "df = prepare.remove_outliers(df)\n",
    "df = prepare.handle_nulls(df)\n",
    "df = prepare.rename_columns(df)\n",
    "df = prepare.prepare_locs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29651757",
   "metadata": {},
   "source": [
    "this looks good for now... let's think about some things to explore-\n",
    "\n",
    "-curious to see if transaction date and log error have any relation, like does the time of year of transation increase/dec likelihood of error?\n",
    "\n",
    "-let's look for like-things... how closely linked are bedroom and bathroom, could they be combined to one feature?\n",
    "\n",
    "-what does the correlatoin to log error chart look like?\n",
    "\n",
    "-what can we bin? keep this in mind through exploration.\n",
    "\n",
    "-look at square feet and year together. do homes get bigger over time?\n",
    "\n",
    "-what if we tried K means on lat, long and square feet?\n",
    "\n",
    "-let's start here and keep adding ideas here when they come up\n",
    "\n",
    "-look at pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy().where(df.square_feet < 1123)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e71f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1131b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123)\n",
    "# Splits data into 3 subsets: train, validate, test. Random state specifying that data is split\n",
    "# with the exact same records when the code is re-run (useful for exploration and modeling, yet\n",
    "# I suggest dropping this when employing the model)\n",
    "\n",
    "def printmd(string): # function to format text style\n",
    "    display(Markdown(string))\n",
    "print()\n",
    "printmd('**Number of Train Records:** {:,}'\n",
    "     .format(len(train)))\n",
    "printmd('**Number of Validate Records:** {:,}'\n",
    "     .format(len(validate)))\n",
    "printmd('**Number of Test Records:** {:,}'\n",
    "     .format(len(test)))\n",
    "# returns the amount of records in each subset after splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5bf8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1810a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler.fit(train[['bathrooms', 'bedrooms', 'square_feet']])\n",
    "# inserts the 4 selected features into the scaler\n",
    "\n",
    "train[['scalbathrooms', 'scalbedrooms', 'scalsquare_feet']] = scaler.transform(train[['bathrooms', 'bedrooms', 'square_feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['scalbathrooms', 'scalbedrooms', 'scalsquare_feet']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "kmeans.fit(X)\n",
    "\n",
    "kmeans.predict(X)\n",
    "\n",
    "train['cluster'] = kmeans.predict(X)\n",
    "\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4281ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler.fit(validate[['bathrooms', 'bedrooms', 'square_feet']])\n",
    "# inserts the 4 selected features into the scaler\n",
    "\n",
    "validate[['scalbathrooms', 'scalbedrooms', 'scalsquare_feet']] = scaler.transform(validate[['bathrooms', 'bedrooms', 'square_feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = validate[['scalbathrooms', 'scalbedrooms', 'scalsquare_feet']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "kmeans.fit(X)\n",
    "\n",
    "kmeans.predict(X)\n",
    "\n",
    "validate['cluster'] = kmeans.predict(X)\n",
    "\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c66ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler.fit(test[['bathrooms', 'bedrooms', 'square_feet']])\n",
    "# inserts the 4 selected features into the scaler\n",
    "\n",
    "test[['scalbathrooms', 'scalbedrooms', 'scalsquare_feet']] = scaler.transform(test[['bathrooms', 'bedrooms', 'square_feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37930ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test[['scalbathrooms', 'scalbedrooms', 'scalsquare_feet']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "kmeans.fit(X)\n",
    "\n",
    "kmeans.predict(X)\n",
    "\n",
    "test['cluster'] = kmeans.predict(X)\n",
    "\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90be0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler.fit(train[['year_built', 'square_feet']])\n",
    "# inserts the 4 selected features into the scaler\n",
    "\n",
    "train[['scalyear', 'scalsquare_feet']] = scaler.transform(train[['year_built', 'square_feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['scalyear', 'scalsquare_feet']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "kmeans.fit(X)\n",
    "\n",
    "kmeans.predict(X)\n",
    "\n",
    "train['cluster2'] = kmeans.predict(X)\n",
    "\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ee4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler.fit(validate[['year_built', 'square_feet']])\n",
    "# inserts the 4 selected features into the scaler\n",
    "\n",
    "validate[['scalyear', 'scalsquare_feet']] = scaler.transform(validate[['year_built', 'square_feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = validate[['scalyear', 'scalsquare_feet']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "kmeans.fit(X)\n",
    "\n",
    "kmeans.predict(X)\n",
    "\n",
    "validate['cluster2'] = kmeans.predict(X)\n",
    "\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e5d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler.fit(test[['year_built', 'square_feet']])\n",
    "# inserts the 4 selected features into the scaler\n",
    "\n",
    "test[['scalyear', 'scalsquare_feet']] = scaler.transform(test[['year_built', 'square_feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test[['scalyear', 'scalsquare_feet']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "kmeans.fit(X)\n",
    "\n",
    "kmeans.predict(X)\n",
    "\n",
    "test['cluster2'] = kmeans.predict(X)\n",
    "\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2b8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5ce38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fdf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8878082",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "plt.xticks(range(2, 12))\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('inertia')\n",
    "plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b39920",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b799d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = train[['latitude', 'longitude']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = train[['latitude', 'longitude']].to_numpy()\n",
    "\n",
    "kmeans.fit(coords)\n",
    "\n",
    "kmeans.predict(coords)\n",
    "\n",
    "train['cluster3'] = kmeans.predict(coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = validate[['latitude', 'longitude']].to_numpy()\n",
    "\n",
    "kmeans.fit(coords)\n",
    "\n",
    "kmeans.predict(coords)\n",
    "\n",
    "validate['cluster3'] = kmeans.predict(coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = test[['latitude', 'longitude']].to_numpy()\n",
    "\n",
    "kmeans.fit(coords)\n",
    "\n",
    "kmeans.predict(coords)\n",
    "\n",
    "test['cluster3'] = kmeans.predict(coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsmall_train = train.copy().where(train.square_feet < 1184)\n",
    "xsmall_train = xsmall_train.dropna()\n",
    "\n",
    "xsmall_validate = validate.copy().where(validate.square_feet < 1184)\n",
    "xsmall_validate = xsmall_validate.dropna()\n",
    "\n",
    "xsmall_test = test.copy().where(test.square_feet < 1184)\n",
    "xsmall_test = xsmall_test.dropna()\n",
    "\n",
    "small = train.copy().where((train.square_feet >= 1184) & (train.square_feet < 1423))\n",
    "small = small.dropna()\n",
    "\n",
    "med = train.copy().where((train.square_feet >= 1423) & (train.square_feet < 1988))\n",
    "med = med.dropna()\n",
    "\n",
    "large = train.copy().where((train.square_feet >= 1988))\n",
    "large = large.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d668df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy1 = pd.get_dummies(train['cluster'])\n",
    "# dummy2 = pd.get_dummies(train['cluster2'])\n",
    "dummy3 = pd.get_dummies(train['cluster3'])\n",
    "\n",
    "# dummy4 = pd.get_dummies(validate['cluster'])\n",
    "# dummy5 = pd.get_dummies(validate['cluster2'])\n",
    "dummy6 = pd.get_dummies(validate['cluster3'])\n",
    "\n",
    "# dummy7 = pd.get_dummies(test['cluster'])\n",
    "# dummy8 = pd.get_dummies(test['cluster2'])\n",
    "dummy9 = pd.get_dummies(test['cluster3'])\n",
    "\n",
    "\n",
    "train = pd.concat([train, dummy3], axis=1)\n",
    "validate = pd.concat([validate, dummy6], axis=1)\n",
    "test = pd.concat([test, dummy9], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc01747",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['cluster3', 'bedrooms', 'bathrooms', 'year_built']]\n",
    "# creates dataframe that drops all column except the selected features for modeling\n",
    "y_train = train[['log_error']]\n",
    "# creates dataframe of target variable (y) only\n",
    "\n",
    "X_validate = validate[['cluster3', 'bedrooms', 'bathrooms', 'year_built']]\n",
    "y_validate = validate[['log_error']]\n",
    "# repeat above for validate set\n",
    "\n",
    "X_test = test[['cluster3', 'bedrooms', 'bathrooms', 'year_built']]\n",
    "y_test = test[['log_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35540fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "# employs the min max scaler\n",
    "scaler.fit(X_train[['bedrooms', 'bathrooms', 'year_built']])\n",
    "# inserts the 4 selected features into the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e33ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af317b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = scaler.transform(X_train[['bedrooms', 'bathrooms', 'year_built']]) \n",
    "v1 = scaler.transform(X_validate[['bedrooms', 'bathrooms', 'year_built']]) \n",
    "v2 = scaler.transform(X_test[['bedrooms', 'bathrooms', 'year_built']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef32d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.DataFrame(data = v)\n",
    "v1 = pd.DataFrame(data = v1)\n",
    "v2 = pd.DataFrame(data = v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.index = X_train.index\n",
    "v1.index = X_validate.index\n",
    "v2.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b713f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, v], axis=1)\n",
    "X_validate = pd.concat([X_validate, v1], axis=1)\n",
    "X_test = pd.concat([X_test, v2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24157f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['bedrooms', 'bathrooms', 'year_built'])\n",
    "# creates dataframe that drops all column except the selected features for modeling\n",
    "y_train = y_train[['log_error']]\n",
    "# creates dataframe of target variable (y) only\n",
    "\n",
    "X_validate = X_validate.drop(columns=['bedrooms', 'bathrooms', 'year_built'])\n",
    "y_validate = y_validate[['log_error']]\n",
    "# repeat above for validate set\n",
    "\n",
    "X_test = X_test.drop(columns=['bedrooms', 'bathrooms', 'year_built'])\n",
    "y_test = y_test[['log_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ddfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_validate[['scaledsize', 'scaledyear']] = scaler.transform(X_validate[['square_feet', 'year_built']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_validate[['scaledsize', 'scaledyear']] = scaler.transform(X_validate[['square_feet', 'year_built']])\n",
    "# X_test[['scaledsize', 'scaledyear']] = data=scaler.transform(X_test[['square_feet', 'year_built']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e820ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.drop(columns = ['square_feet', 'year_built'])\n",
    "# X_validate = X_validate.drop(columns = ['square_feet', 'year_built'])\n",
    "# X_test = X_test.drop(columns = ['square_feet','year_built'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['pred_mean'] = y_train.log_error.mean()\n",
    "y_validate['pred_mean'] = y_validate.log_error.mean()\n",
    "# calculates mean prior to computing rmse\n",
    "\n",
    "rmse_train = mean_squared_error(y_train.log_error, y_train.pred_mean)**(1/2)\n",
    "rmse_validate = mean_squared_error(y_validate.log_error, y_validate.pred_mean)**(1/2)\n",
    "# computes baseline RMSE for train and validate sets (square root of MSE)\n",
    "\n",
    "print(\"Baseline RMSE\\nTrain/In-Sample: \", (rmse_train)), \n",
    "print(\"Baseline RMSE\\nValidate/Out-of-Sample: \", (rmse_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lm = LinearRegression(normalize=True)\n",
    "# create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lm.fit(X_train, y_train.log_error)\n",
    "# fit the model to scaled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train['value_predict_lm'] = lm.predict(X_train)\n",
    "# computes model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse_train = mean_squared_error(y_train.log_error, y_train.value_predict_lm)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200801a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_validate['value_predict_lm'] = lm.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22a1c21",
   "metadata": {},
   "source": [
    "lm = LinearRegression(normalize=True)\n",
    "# create the model\n",
    "\n",
    "lm.fit(X_train, y_train.log_error)\n",
    "# fit the model to scaled training data\n",
    "\n",
    "y_train['value_predict_lm'] = lm.predict(X_train)\n",
    "# computes model predictions\n",
    "\n",
    "rmse_train = mean_squared_error(y_train.log_error, y_train.value_predict_lm)**(1/2)\n",
    "# computes model rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbe96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d87954",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression(normalize=True)\n",
    "# create the model\n",
    "\n",
    "lm.fit(X_train, y_train.log_error)\n",
    "# fit the model to scaled training data\n",
    "\n",
    "y_train['value_predict_lm'] = lm.predict(X_train)\n",
    "# computes model predictions\n",
    "\n",
    "rmse_train = mean_squared_error(y_train.log_error, y_train.value_predict_lm)**(1/2)\n",
    "# computes model rmse\n",
    "\n",
    "y_validate['value_predict_lm'] = lm.predict(X_validate)\n",
    "rmse_validate = mean_squared_error(y_validate.log_error, y_validate.value_predict_lm)**(1/2)\n",
    "# comutes predictions and rmse with validate data\n",
    "\n",
    "printmd(\"**OLS Linear Regression Performance**\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", (rmse_train))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE for OLS using LinearRegression\\nValidation/Out-of-Sample: \", (rmse_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473b005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['value_predict_lm'].mean() < y_train['log_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb07c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['value_predict_lm'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['log_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03d895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0985dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aad3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae38a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa8ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024094c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd7d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c7a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f604a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86263d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed011fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b48f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a9135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small = train.copy().where((train.square_feet >= 1184) & (train.square_feet < 1393))\n",
    "# small = small.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ddc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlarge = train.copy().where(train.square_feet >= 4000)\n",
    "# xlarge = large.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d29728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlarge = train.copy().where(train.square_feet >= 2000)\n",
    "# xlarge = large.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e744f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
